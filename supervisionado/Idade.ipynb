{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# Abrindo o CSV\n",
    "data = genfromtxt('dataset/data_limpo_semINTMAX.csv', delimiter=',')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando apenas as entradas e saidas\n",
    "\n",
    "idade = data[1: , 163] # Idade\n",
    "acuracia = data[1:, 165] # Acuracia\n",
    "\n",
    "data = data[1: , 0:163] # Perguntas\n",
    "\n",
    "(nData, nFeatures) = data.shape\n",
    "\n",
    "print('nData: ', nData)\n",
    "print('nFeatures: ', nFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando apenas os 16 resultados\n",
    "\n",
    "# Abrindo o CSV\n",
    "data16 = genfromtxt('dataset/output_limpo_semINTMAX.csv', delimiter=',')\n",
    "print(data16)\n",
    "\n",
    "# Sobrescreve as perguntas com os 16 resultados\n",
    "data = data16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando as idades\n",
    "\n",
    "gIdade = idade\n",
    "\n",
    "for i in range(0, nData):\n",
    "    if idade[i] < 20:\n",
    "        gIdade[i] = 0\n",
    "        \n",
    "    elif idade[i] < 40:\n",
    "        gIdade[i] = 1\n",
    "        \n",
    "    elif idade[i] < 60:\n",
    "        gIdade[i] = 2\n",
    "        \n",
    "    else:\n",
    "        gIdade[i] = 3\n",
    "\n",
    "classes = ['0', '1', '2', '3']\n",
    "\n",
    "print(gIdade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em dados de teste e treino\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(dataTrain, dataTest, yTrain, yTest, acuraciaTrain, acuraciaTest) = train_test_split(data, idade, acuracia, test_size = 0.1, shuffle=True)\n",
    "\n",
    "print(dataTrain.shape, yTrain.shape)\n",
    "print(dataTest.shape, yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.9, svd_solver='full')\n",
    "pca.fit(dataTrain)\n",
    "dataTrain = pca.transform(dataTrain)\n",
    "dataTest = pca.transform(dataTest)\n",
    "\n",
    "print(dataTrain.shape, dataTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Linear sem Acurácia\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "md = LinearRegression(\n",
    "            fit_intercept=True,\n",
    "            normalize=True,\n",
    "            copy_X=True,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "md.fit(dataTrain, yTrain)\n",
    "print('Train: ', md.score(dataTrain, yTrain))\n",
    "print('Test:  ', md.score(dataTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Linear com Acurácia\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "md = LinearRegression(\n",
    "            fit_intercept=True,\n",
    "            normalize=True,\n",
    "            copy_X=True,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "md.fit(dataTrain, yTrain, sample_weight=acuraciaTrain)\n",
    "print('Train: ', md.score(dataTrain, yTrain, sample_weight=acuraciaTrain))\n",
    "print('Test:  ', md.score(dataTest, yTest, sample_weight=acuraciaTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "md = LinearSVC(\n",
    "            penalty='l2',\n",
    "            loss='squared_hinge',\n",
    "            dual=True,\n",
    "            tol=1e-4,\n",
    "            C=1.0,\n",
    "            multi_class='ovr',\n",
    "            fit_intercept=True,\n",
    "            intercept_scaling=1,\n",
    "            verbose=1,\n",
    "            random_state=None,\n",
    "            max_iter=100000\n",
    "        )\n",
    "\n",
    "md.fit(dataTrain, yTrain)\n",
    "print('Train: ', md.score(dataTrain, yTrain))\n",
    "print('Test: ', md.score(dataTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron sem Acurácia\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "md = Perceptron(\n",
    "            penalty='l2',\n",
    "            alpha=1e-8,\n",
    "            fit_intercept=True,\n",
    "            max_iter=1e6,\n",
    "            tol=1e-5,\n",
    "            shuffle=True,\n",
    "#             verbose=1,\n",
    "            eta0=0.5,\n",
    "            n_jobs=-1,\n",
    "            random_state=None,\n",
    "            class_weight=None,\n",
    "            warm_start=False,\n",
    "        )\n",
    "\n",
    "md.fit(dataTrain, yTrain)\n",
    "print('Train: ', md.score(dataTrain, yTrain))\n",
    "print('Test:  ', md.score(dataTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron com Acurácia\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "md = Perceptron(\n",
    "            penalty='l2',\n",
    "            alpha=1e-8,\n",
    "            fit_intercept=True,\n",
    "            max_iter=1e6,\n",
    "            tol=1e-5,\n",
    "            shuffle=True,\n",
    "#             verbose=1,\n",
    "            eta0=0.5,\n",
    "            n_jobs=-1,\n",
    "            random_state=None,\n",
    "            class_weight=None,\n",
    "            warm_start=False,\n",
    "        )\n",
    "\n",
    "md.fit(dataTrain, yTrain, sample_weight=acuraciaTrain)\n",
    "print('Train: ', md.score(dataTrain, yTrain, sample_weight=acuraciaTrain))\n",
    "print('Test:  ', md.score(dataTest, yTest, sample_weight=acuraciaTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma rede neural\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "md = MLPClassifier(\n",
    "            hidden_layer_sizes = (25),\n",
    "            activation = 'identity',\n",
    "            solver = 'sgd',\n",
    "            alpha = 1e-6,\n",
    "            batch_size = 'auto',\n",
    "            learning_rate = 'adaptive',\n",
    "            learning_rate_init = 0.001,\n",
    "            power_t = 0.5,\n",
    "            max_iter = 10000,\n",
    "            shuffle = True,\n",
    "            random_state = None,\n",
    "            tol = 1e-4,\n",
    "            verbose = True,\n",
    "            warm_start = False,\n",
    "            momentum = 0.9,\n",
    "            nesterovs_momentum = True,\n",
    "            early_stopping = False,\n",
    "            validation_fraction = 0.15    \n",
    "        )\n",
    "\n",
    "md.fit(dataTrain, yTrain)\n",
    "print('Train: ', md.score(dataTrain, yTrain))\n",
    "print('Test:  ', md.score(dataTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as entradas de idades com predições corretas em diferentes arquivos\n",
    "\n",
    "# Predizemos nossos dados\n",
    "yPred = md.predict(dataTest)\n",
    "\n",
    "(nDataTest, nFeaturesTest) = dataTest.shape\n",
    "\n",
    "# Para idades de 13 a 80 anos\n",
    "for idd in range(13, 80):\n",
    "    # Criamos uma matriz\n",
    "    dados_copia = numpy.zeros(dataTest.shape)\n",
    "    \n",
    "    # Indices\n",
    "    i=0\n",
    "    j=dataTest.shape[0]-1\n",
    "    p=0\n",
    "    \n",
    "    # Preenchemos a matriz de tal forma que os dados com predição correta fiquem no começo, e os dados com predição errada fiquem no final\n",
    "    while (i<=j):\n",
    "        if (int(yPred[p]) == idd):\n",
    "            dados_copia[i] = dataTest[p]\n",
    "            i = i+1\n",
    "        else:\n",
    "            dados_copia[j] = dataTest[p]\n",
    "        j = j-1\n",
    "\n",
    "        p = p+1\n",
    "\n",
    "    # Pegamos apenas os dados que foram preditos corretamente\n",
    "    dados_copia = dados_copia[0:i][:]\n",
    "\n",
    "\n",
    "    # Salva tais dados em um arquivo CSV\n",
    "    numpy.savetxt('idades/'+str(igual)+'.csv', dados_copia, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Primeiro, os dados tem os valores de cada tem: yTest\n",
    "# Agora vou montar meu vetor de predições: yPredict\n",
    "\n",
    "yPred = md.predict(dataTest)\n",
    "classes = ['13-20', '20-40', '40-60', '60-']\n",
    "\n",
    "matrix = confusion_matrix(yTest, yPred)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, numpy.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = numpy.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    \n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(matrix,classes=classes, title='Confusion matrix, without normalization')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
